{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Domains-and-glossary.xlsx'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6b32a8b8bc99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxls_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Domains-and-glossary.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxls_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Domains-and-glossary.xlsx'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "xls_file = pd.ExcelFile('Domains-and-glossary.xlsx')\n",
    "\n",
    "print(xls_file.sheet_names)\n",
    "\n",
    "\n",
    "df = xls_file.parse('Glossary (by domain)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_w2v(word2vec_model_file):\n",
    "    # load the finished model from disk\n",
    "    word2vec_model = Word2Vec.load(word2vec_model_file)\n",
    "    word2vec_model.init_sims(replace=True)\n",
    "    return word2vec_model\n",
    "\n",
    "word2vec_model_file = '/home/sonic/sonic/eosdb/data/eos/word2vec_model_all.model'\n",
    "word2vec_model = load_w2v(word2vec_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = df['Violence'][1:]\n",
    "\n",
    "keywords = keywords.dropna(how='any')\n",
    "# print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "keyword_w2v = []\n",
    "\n",
    "for word in keywords:\n",
    "#     print(document_vector(word2vec_model, doc))\n",
    "\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in word.split() if word in word2vec_model.wv.vocab]\n",
    "    if len(doc) == 0:\n",
    "        continue\n",
    "    \n",
    "    keyword_w2v.append(document_vector(word2vec_model, doc))\n",
    "    \n",
    "keyword_w2v = np.array(keyword_w2v)\n",
    "# # # Scaled\n",
    "# X_embedded_scaled = preprocessing.scale(topic_w2v)\n",
    "X_normalized = preprocessing.normalize(keyword_w2v, norm='l2')\n",
    "\n",
    "\n",
    "print(len(keyword_w2v))\n",
    "print(keyword_w2v[0])\n",
    "# print(X_embedded_scaled[0])\n",
    "# print(X_normalized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03559574 -0.04429134  0.1150565  ..., -0.0234171   0.00550879\n",
      "  -0.0983898 ]\n",
      " [-0.03052965 -0.11964951  0.07880859 ..., -0.017168   -0.10105554\n",
      "  -0.03308823]\n",
      " [ 0.00585283 -0.10805272  0.07068779 ..., -0.01099878 -0.06338074\n",
      "  -0.08180024]\n",
      " ..., \n",
      " [-0.01316302 -0.16323963  0.04590257 ..., -0.02707528 -0.12101123\n",
      "  -0.06573825]\n",
      " [ 0.08877812 -0.08373272  0.04539325 ..., -0.08314145 -0.0118684\n",
      "  -0.08342692]\n",
      " [ 0.03137421 -0.09060578  0.10033997 ..., -0.03020529 -0.06571938\n",
      "  -0.05896141]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can</td>\n",
       "      <td>will</td>\n",
       "      <td>one</td>\n",
       "      <td>year</td>\n",
       "      <td>go</td>\n",
       "      <td>like</td>\n",
       "      <td>get</td>\n",
       "      <td>make</td>\n",
       "      <td>people</td>\n",
       "      <td>say</td>\n",
       "      <td>time</td>\n",
       "      <td>good</td>\n",
       "      <td>world</td>\n",
       "      <td>know</td>\n",
       "      <td>see</td>\n",
       "      <td>just</td>\n",
       "      <td>now</td>\n",
       "      <td>work</td>\n",
       "      <td>think</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shelling</td>\n",
       "      <td>damascus</td>\n",
       "      <td>suburbs</td>\n",
       "      <td>regime</td>\n",
       "      <td>homs</td>\n",
       "      <td>neighborhood</td>\n",
       "      <td>idlib</td>\n",
       "      <td>forces</td>\n",
       "      <td>daraa</td>\n",
       "      <td>report</td>\n",
       "      <td>fierce</td>\n",
       "      <td>hama</td>\n",
       "      <td>town</td>\n",
       "      <td>fsa</td>\n",
       "      <td>city</td>\n",
       "      <td>martyrs</td>\n",
       "      <td>artillery</td>\n",
       "      <td>al</td>\n",
       "      <td>mortar</td>\n",
       "      <td>army</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>syrian</td>\n",
       "      <td>syria</td>\n",
       "      <td>assad</td>\n",
       "      <td>opposition</td>\n",
       "      <td>talk</td>\n",
       "      <td>geneva</td>\n",
       "      <td>say</td>\n",
       "      <td>foreign</td>\n",
       "      <td>arab</td>\n",
       "      <td>peace</td>\n",
       "      <td>al_assad</td>\n",
       "      <td>regime</td>\n",
       "      <td>damascus</td>\n",
       "      <td>government</td>\n",
       "      <td>president_bashar</td>\n",
       "      <td>meeting</td>\n",
       "      <td>political</td>\n",
       "      <td>conference</td>\n",
       "      <td>support</td>\n",
       "      <td>terrorism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>israel</td>\n",
       "      <td>israeli</td>\n",
       "      <td>palestinian</td>\n",
       "      <td>jerusalem</td>\n",
       "      <td>palestinians</td>\n",
       "      <td>hamas</td>\n",
       "      <td>gaza</td>\n",
       "      <td>netanyahu</td>\n",
       "      <td>west_bank</td>\n",
       "      <td>jewish</td>\n",
       "      <td>israelis</td>\n",
       "      <td>peace</td>\n",
       "      <td>aqsa</td>\n",
       "      <td>abbas</td>\n",
       "      <td>palestine</td>\n",
       "      <td>arab</td>\n",
       "      <td>jews</td>\n",
       "      <td>jordan</td>\n",
       "      <td>benjamin_netanyahu</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>turkey</td>\n",
       "      <td>turkish</td>\n",
       "      <td>erdogan</td>\n",
       "      <td>ankara</td>\n",
       "      <td>kurdish</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>pkk</td>\n",
       "      <td>border</td>\n",
       "      <td>syria</td>\n",
       "      <td>davutoglu</td>\n",
       "      <td>kurds</td>\n",
       "      <td>tayyip_erdogan</td>\n",
       "      <td>syrian</td>\n",
       "      <td>nato</td>\n",
       "      <td>party</td>\n",
       "      <td>ypg</td>\n",
       "      <td>armenian</td>\n",
       "      <td>recep_tayyip</td>\n",
       "      <td>visit</td>\n",
       "      <td>coup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1            2           3             4             5   \\\n",
       "0       can      will          one        year            go          like   \n",
       "1  shelling  damascus      suburbs      regime          homs  neighborhood   \n",
       "2    syrian     syria        assad  opposition          talk        geneva   \n",
       "3    israel   israeli  palestinian   jerusalem  palestinians         hamas   \n",
       "4    turkey   turkish      erdogan      ankara       kurdish      istanbul   \n",
       "\n",
       "      6          7          8          9         10              11        12  \\\n",
       "0    get       make     people        say      time            good     world   \n",
       "1  idlib     forces      daraa     report    fierce            hama      town   \n",
       "2    say    foreign       arab      peace  al_assad          regime  damascus   \n",
       "3   gaza  netanyahu  west_bank     jewish  israelis           peace      aqsa   \n",
       "4    pkk     border      syria  davutoglu     kurds  tayyip_erdogan    syrian   \n",
       "\n",
       "           13                14       15         16            17  \\\n",
       "0        know               see     just        now          work   \n",
       "1         fsa              city  martyrs  artillery            al   \n",
       "2  government  president_bashar  meeting  political    conference   \n",
       "3       abbas         palestine     arab       jews        jordan   \n",
       "4        nato             party      ypg   armenian  recep_tayyip   \n",
       "\n",
       "                   18         19  \n",
       "0               think       many  \n",
       "1              mortar       army  \n",
       "2             support  terrorism  \n",
       "3  benjamin_netanyahu      state  \n",
       "4               visit       coup  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_nmf_dynamic_topics(k, dictionary, topn=20):\n",
    "    \n",
    "    topic_list = []\n",
    "    topic_df = pd.read_pickle('../dynamic_nmf/data/windowbin/result/dynamic.df/dynamic_k%s.pkl' % (k))\n",
    "\n",
    "    for c in topic_df.ix[:,1:].columns:\n",
    "        # filter out any token not in \n",
    "        if dictionary is not None:\n",
    "            topic = [x for x in topic_df[c].tolist() if x in dictionary.token2id.keys()]\n",
    "        else:\n",
    "            topic = topic_df[c].tolist() \n",
    "        topic_list.append(topic[:topn])\n",
    "        \n",
    "#     print(topic_list)\n",
    "    return topic_list\n",
    "\n",
    "\n",
    "# print(get_nmf_dynamic_topics(42, None, 20))  \n",
    "df = pd.DataFrame(get_nmf_dynamic_topics(42, None, 20))\n",
    "df.to_csv('dynamic_nmf_42.csv')\n",
    "\n",
    "\n",
    "topic_w2v = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "#     print(row)\n",
    "    doc = [word for word in row if word in word2vec_model.wv.vocab]\n",
    "    if len(doc) == 0:\n",
    "        continue\n",
    "        \n",
    "    topic_w2v.append(document_vector(word2vec_model, doc))\n",
    "#     break\n",
    "\n",
    "topic_w2v = np.array(topic_w2v)\n",
    "\n",
    "print(topic_w2v)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "A = np.array([[i] for i in range(len(corpus))])\n",
    "\n",
    "print (A)\n",
    "\n",
    "def f(x, y):\n",
    "    return word2vec_model.wv.wmdistance(corpus[int(x)], corpus[int(y)])\n",
    "\n",
    "X_wmd_distance_eos = pairwise_distances(A, metric=f, n_jobs=-1)\n",
    "\n",
    "df_X_wmd_distance_eos = pd.DataFrame(X_wmd_distance_eos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}