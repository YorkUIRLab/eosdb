{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gzip\n",
    "import logging\n",
    "import operator\n",
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.1 s, sys: 1.21 s, total: 22.4 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "import operator\n",
    "import codecs\n",
    "\n",
    "class MyDocuments(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        with gzip.open(self.dirname, 'rb') as f:\n",
    "            for line in f:\n",
    "                yield line.decode('utf-8', 'ignore').split('\\t')[1].split()\n",
    "                \n",
    "                \n",
    "x = MyDocuments('data/eos/ngram/bigram_transformed_docs_%s.gz' % 'all')\n",
    "\n",
    "with codecs.open('data/eos/ngram/bigram_transformed_docs_all.txt', \"w\", \"utf-8\") as targetFile:\n",
    "    \n",
    "    for sentence_no, sentence in enumerate(x):\n",
    "    #   print(sentence_no)\n",
    "    #   print(sentence)\n",
    "        targetFile.write(u' '.join(sentence)  + u' \\n')\n",
    "    #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def generate_fastText(corpus_path, model_file):\n",
    "    \n",
    "    print(\"starting epoche \" + time.strftime(\"%H:%M:%S\"))\n",
    "    # initiate the model and perform the first epoch of training\n",
    "    \n",
    "    model = gensim.models.wrappers.fasttext.FastText.train(ft_path='/home/sonic/sonic/fastText/fasttext', \n",
    "                                                           corpus_file=corpus_path)\n",
    "    \n",
    "    model.save(model_file)\n",
    "    print(\"Finished epoche \" + time.strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "    print (\"{} training epochs so far\".format(model.train_count))\n",
    "    print (\"{:,} terms in the FastText EOS vocabulary.\".format(len(model.wv.vocab)))\n",
    "\n",
    "def load_fastText(model_file):\n",
    "    # load the finished model from disk\n",
    "    model = Word2Vec.load(model_file)\n",
    "#     model.init_sims(replace=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/eos/ngram/bigram_transformed_docs_all.txt\n",
      "starting epoche 00:35:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-14 01:00:10,907 : INFO : loading projection weights from /tmp/ft_model.vec\n",
      "2017-07-14 01:00:51,840 : INFO : loaded (671085, 100) matrix from /tmp/ft_model.vec\n",
      "2017-07-14 01:01:45,548 : INFO : saving FastText object under data/eos/fastText_model_all.model, separately None\n",
      "2017-07-14 01:01:45,548 : INFO : storing np array 'syn0' to data/eos/fastText_model_all.model.wv.syn0.npy\n",
      "2017-07-14 01:01:45,932 : INFO : not storing attribute syn0_all_norm\n",
      "2017-07-14 01:01:45,933 : INFO : storing np array 'syn0_all' to data/eos/fastText_model_all.model.wv.syn0_all.npy\n",
      "2017-07-14 01:01:48,781 : INFO : not storing attribute syn0norm\n",
      "2017-07-14 01:01:51,379 : INFO : saved data/eos/fastText_model_all.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoche 01:01:51\n",
      "0 training epochs so far\n",
      "671,085 terms in the FastText EOS vocabulary.\n",
      "CPU times: user 1min 37s, sys: 2.03 s, total: 1min 39s\n",
      "Wall time: 26min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load EOS processed corpus\n",
    "corpus_path = 'data/eos/ngram/bigram_transformed_docs_all.txt'\n",
    "print(corpus_path)\n",
    "\n",
    "model_file = 'data/eos/fastText_model_all.model'\n",
    "\n",
    "generate_fastText(corpus_path, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-14 01:01:52,660 : INFO : loading Word2Vec object from data/eos/fastText_model_all.model\n",
      "2017-07-14 01:01:55,214 : INFO : loading wv recursively from data/eos/fastText_model_all.model.wv.* with mmap=None\n",
      "2017-07-14 01:01:55,217 : INFO : loading syn0 from data/eos/fastText_model_all.model.wv.syn0.npy with mmap=None\n",
      "2017-07-14 01:01:55,281 : INFO : loading syn0_all from data/eos/fastText_model_all.model.wv.syn0_all.npy with mmap=None\n",
      "2017-07-14 01:01:55,539 : INFO : setting ignored attribute syn0_all_norm to None\n",
      "2017-07-14 01:01:55,540 : INFO : setting ignored attribute syn0norm to None\n",
      "2017-07-14 01:01:55,540 : INFO : loaded data/eos/fastText_model_all.model\n"
     ]
    }
   ],
   "source": [
    "model = load_fastText(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-14 01:01:57,965 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-07-14 01:01:58,138 : INFO : precomputing L2-norms of ngram weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('\\x97obama', 0.9707701802253723),\n",
       " ('obama`s', 0.9619391560554504),\n",
       " ('obama\\x92s', 0.9568393230438232),\n",
       " ('obamas', 0.8678238987922668),\n",
       " ('obama_habló', 0.8510994911193848),\n",
       " ('sot_obama', 0.8376156687736511),\n",
       " ('obamaâ€™s', 0.8316937685012817),\n",
       " ('obamacare', 0.8098371028900146),\n",
       " ('sopel_obama', 0.8093130588531494),\n",
       " ('barack_obama', 0.7969828248023987)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(model['trump'])\n",
    "model.similar_by_word('obama', topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
