{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "import gensim.models.doc2vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim\n",
    "import sys\n",
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "import csv\n",
    "import _pickle as cPickle\n",
    "from sklearn.externals import joblib\n",
    "import bz2\n",
    "from random import shuffle\n",
    "import ast\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/eos_tokens_stopwords.txt\") as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "doc2vec_data = []\n",
    "for line in data:\n",
    "    line = ast.literal_eval(line)\n",
    "    temp = ' '.join(str(token) for token in line)\n",
    "    doc2vec_data.append(temp)\n",
    "    \n",
    "File = open('data/doc2vec_data.txt', 'w') \n",
    "for item in doc2vec_data:\n",
    "    File.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences=gensim.models.doc2vec.TaggedLineDocument(\"data/doc2vec_data.txt\")\n",
    "model = gensim.models.doc2vec.Doc2Vec(sentences, size=200, window=10, min_count=5, iter=20, workers=8)\n",
    "\n",
    "model.save('doc2vec_model.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('doc2vec_model.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5377, 0.5258454084396362), (5599, 0.37886685132980347), (5590, 0.36026638746261597), (7184, 0.3549143075942993), (9802, 0.34451237320899963), (4488, 0.34104377031326294), (3348, 0.34001803398132324), (814, 0.3253442645072937), (4050, 0.32484573125839233), (8534, 0.3236147165298462)]\n"
     ]
    }
   ],
   "source": [
    "#The full model was run on a server. The first output below is a sample model run on 1000 lines\n",
    "#of text. The markdown cell below the output is the output on the server for 30 million lines.\n",
    "sims = model.docvecs.most_similar(99)\n",
    "\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the same sims = model.docvecs.most_similar(99); print(sims); command but run on the full model.\n",
    "\n",
    "[(98, 0.8011916875839233), (15987504, 0.5732544660568237), (9361116, 0.56634122133255), (15987503, 0.5599271655082703), (9361115, 0.5523300170898438), (15987502, 0.5513883829116821), (16801862, 0.5123482942581177), (16801861, 0.5077716112136841), (11492322, 0.5020641088485718), (755432, 0.48910319805145264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diplomat\n",
      "yellow\n",
      "fall\n",
      "winter\n",
      "[('sheikh', 0.29759371280670166), ('abdullah', 0.2927790582180023), ('gcc', 0.2861786484718323), ('shaikh', 0.27961617708206177), ('bin', 0.2788739800453186), ('abdulaziz', 0.27637121081352234), ('nayef', 0.2659643888473511), ('renew', 0.2647008001804352), ('indian', 0.26459500193595886), ('hrh', 0.26205959916114807)]\n",
      "[('couldn', 0.5273951292037964), ('iba', 0.5182523727416992), ('voorheen', 0.4993104636669159), ('aren', 0.499233216047287), ('kearney', 0.4980449676513672), ('hadn', 0.4979991316795349), ('actueel', 0.49152493476867676), ('wasn', 0.4747185707092285), ('elijah', 0.4691956639289856), ('weren', 0.4674947261810303)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'tommy' not in vocabulary\"",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-741cfaac0023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'saudi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'king'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'girl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shirt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calvin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'klein'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tommy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cotton'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'material'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polyester'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nike'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'run'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'express'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \"\"\"\n\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwmdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'tommy' not in vocabulary\""
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(model.doesnt_match(\"iran diplomat scarf\".split()))\n",
    "print(model.doesnt_match(\"black blue yellow shirt navy black green orange\".split()))\n",
    "print(model.doesnt_match(\"summer winter fall t-shirt spring hot cold\".split()))\n",
    "print(model.doesnt_match(\"straight slim fit custom regular winter\".split()))\n",
    "\n",
    "\n",
    "print(model.most_similar(positive=['saudi', 'king'], negative=['girl']))\n",
    "print(model.most_similar(positive=['blue', 'shirt'], negative=['blue']))\n",
    "print(model.most_similar(positive=['calvin', 'klein'], negative=['tommy']))\n",
    "print(model.most_similar(positive=['cotton', 'material'], negative=['polyester']))\n",
    "print(model.most_similar(positive=['nike', 'run'], negative=['express']))\n",
    "\n",
    "\n",
    "\n",
    "print(model.most_similar_cosmul(positive=['calvin', 'klein'], negative=['tommy']) )\n",
    "print(model.most_similar_cosmul(positive=['skinny', 'jean'], negative=['large']) )\n",
    "print(model.most_similar_cosmul(positive=['black', 'dress'], negative=['navy']) )\n",
    "print(model.most_similar_cosmul(positive=['blue', 'coat'], negative=['yellow']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands below were run on a server. Below are the ouputs from the server. View the youtube video tutorial for a more in depth explanation. \n",
    "\n",
    "scarf\n",
    "\n",
    "\n",
    "shirt\n",
    "\n",
    "\n",
    "t-shirt\n",
    "\n",
    "\n",
    "winter\n",
    "\n",
    "\n",
    "[('national', 0.7366822957992554), ('deluxe', 0.7351764440536499), ('gangster', 0.7151539921760559), ('redhead', 0.706986665725708), ('jedi', 0.7043461203575134), ('hurley', 0.7041280269622803), ('police', 0.6921283602714539), ('vampire', 0.6920264959335327), ('elvis', 0.6828189492225647), ('man', 0.6826508045196533)]\n",
    "\n",
    "\n",
    "[('sport-shirt', 0.7597200870513916), ('shirt-shirt', 0.6976513862609863), ('blazer', 0.6822149753570557), ('jacket', 0.6756230592727661), ('jogger', 0.6722015142440796), ('t-shirt', 0.6683749556541443), ('vest', 0.6655105352401733), ('fever', 0.6630758047103882), ('mango', 0.6513298749923706), ('sweatshirt', 0.6464142799377441)]\n",
    "\n",
    "\n",
    "[('hilfiger', 0.7638254165649414), ('bahama', 0.7248090505599976), ('dkny', 0.7199745178222656), ('cabela', 0.6731507182121277), ('aura', 0.6693034172058105), ('research', 0.6658661365509033), ('average', 0.6650013327598572), ('panache', 0.6622791886329651), ('jezebel', 0.6556996703147888), ('anita', 0.6532233357429504)]\n",
    "\n",
    "\n",
    "[('lightweight', 0.7339928150177002), ('fabric', 0.714056670665741), ('soft', 0.6978321671485901), ('microfiber', 0.6879997253417969), ('premium', 0.6641561985015869), ('craft', 0.6537737846374512), ('stretchy', 0.6503570079803467), ('jersey', 0.6496517062187195), ('silken', 0.6456028819084167), ('durable', 0.6450238823890686)]\n",
    "\n",
    "\n",
    "[('training', 0.6947599649429321), ('armour', 0.661718487739563), ('active', 0.6468547582626343), ('circuit', 0.6453198194503784), ('pace', 0.6296043395996094), ('speedo', 0.6284787654876709), ('reebok', 0.6192759275436401), ('tyr', 0.613123893737793), ('triathlon', 0.6078574657440186), ('running', 0.6044196486473083)]\n",
    "\n",
    "\n",
    "[('hilfiger', 3.4731686115264893), ('bahama', 3.238680362701416), ('cabela', 1.4618180990219116), ('average', 1.4044843912124634), ('hilfger', 1.403147578239441), ('vanderbilt', 1.390093445777893), ('island', 1.3801980018615723), ('vassarette', 1.3763628005981445), ('voi', 1.3734792470932007), ('mavi', 1.363916277885437)]\n",
    "\n",
    "\n",
    "[('ankle', 2.0474910736083984), ('bootcut', 2.024974822998047), ('tapered', 2.005871534347534), ('straight', 1.9957698583602905), ('slouch', 1.9716737270355225), ('boot', 1.915338397026062), ('boyfriend', 1.8978936672210693), ('pant', 1.7995022535324097), ('trouser', 1.7738025188446045), ('duty', 1.728303074836731)]\n",
    "\n",
    "\n",
    "[('blouse', 0.9562901258468628), ('skirt', 0.9473488926887512), ('gown', 0.9371359944343567), ('jumpsuit', 0.9135350584983826), ('milly', 0.8995895385742188), ('romper', 0.8857595920562744), ('dvf', 0.8833042979240417), ('caftan', 0.8828949928283691), ('nordstromrack', 0.882025957107544), ('top', 0.8750998973846436)]\n",
    "\n",
    "\n",
    "[('gilet', 0.9358639121055603), ('df', 0.9223589897155762), ('jumper', 0.912643551826477), ('ba', 0.9119251370429993), ('bd', 0.9087516665458679), ('parka', 0.906380295753479), ('jacket', 0.9058188796043396), ('azure', 0.905199408531189), ('blazer', 0.8978071212768555), ('bf', 0.8966451287269592)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}